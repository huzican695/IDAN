
import torch
import torch.nn as nn
from torchvision import models
from torchvision.models._utils import IntermediateLayerGetter
import cv2
import numpy as np
import os
import math
import torch.nn.functional as F
import torch.optim as optim
from torchvision import datasets, transforms, models, utils
from torchvision.transforms import Compose, CenterCrop, ToTensor, Resize
from torch.utils.data import DataLoader, Dataset, random_split
import matplotlib.pyplot as plt
import time
import copy
import random
import argparse
from tqdm import tqdm
#from tensorboardX import SummaryWriter
import shutil
"""-----------------------------------------------超参数----------------------------------------------"""

parser = argparse.ArgumentParser(description="Choose mode")
parser.add_argument('-mode', type=str, default='train')
parser.add_argument('-dim', type=int, default=64)
parser.add_argument('-num_epochs', type=int, default=2000)
parser.add_argument('-image_scale_h', type=int, default=512)
parser.add_argument('-image_scale_w', type=int, default=512)
parser.add_argument('-batch', type=int, default=4)
parser.add_argument('-lr', type=float, default=1e-4)#1e-4 refinenet：5e-5 0.001
parser.add_argument('-lr_1', type=float, default=5e-5)#5e-5
parser.add_argument('-img_before_path', type=str, default='./5_1/train/before/')
parser.add_argument('-img_after_path', type=str, default="./5_1/train/after/")
parser.add_argument('-label_path', type=str, default='./5_1/train/change_label/')

parser.add_argument('-img_before_path_test', type=str, default='./5_1/test/before/')
parser.add_argument('-img_after_path_test', type=str, default="./5_1/test/after/")
parser.add_argument('-label_path_test', type=str, default='./5_1/test/change_label/')

parser.add_argument('-model_dir', type=str, default='./cdnet_pre_T/model/model.pkl')
parser.add_argument('-model_dir_max', type=str, default='./cdnet_pre_T/max_model/model.pkl')
parser.add_argument('-result', type=str, default='./cdnet_pre_T/result/')
parser.add_argument('-result_max', type=str, default='./cdnet_pre_T/max_result/')
parser.add_argument('-txt', type=str, default='./cdnet_pre_T/hzc.txt')

#writer = SummaryWriter('./other/log1/deeplab+_munich/')
parser.add_argument('-gpu', type=str, default='2')
parser.add_argument('-load_model',type=str, default='Tru')
opt = parser.parse_args()
os.environ["CUDA_VISIBLE_DEVICES"] = opt.gpu
use_cuda = torch.cuda.is_available()
print("use_cuda:", use_cuda)
device = torch.device("cuda" if use_cuda else "cpu")
#device1 = torch.device("cuda" if use_cuda else "cpu",3)
def file_filter(f):
    if f[-4:] in ['.jpg', '.png', '.bmp']:
        return True
    else:
        return False

def seed_torch(seed=8):
    random.seed(seed)
    os.environ['PYTHONHASHSEED'] = str(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)  # if you are using multi-GPU.
    # torch.backends.cudnn.benchmark = False
    # torch.backends.cudnn.deterministic = True
"""----------------------------------------预训练感知差分信息------------------------------------"""
#预训练模型提取特征
class build_pre_model(nn.Module):
    def __init__(self, pre_training_model='VGG16'):
        super(build_pre_model, self).__init__()
        if pre_training_model == 'MobileNetV2':
            self.model = models.mobilenet_v2(pretrained=True)
        if pre_training_model == 'ResNet50V2':
            self.model = models.resnet50(pretrained=True)
        if pre_training_model == 'VGG16':
            self.model = models.vgg16(pretrained=True)
    def forward(self, x):
        k = len(self.model.features) #31
        for i in range(k):
            x = self.model.features[i](x)
            if i == 3:
                out1 = x
            if i == 8:
                out2 = x
            if i == 15:
                out3 = x
            if i == 22:
                out4 = x
            if i == 29:
                out5 = x
        # size, size/2, size/4, size/8, size/16
        #out = [out1,out2,out3,out4,out5]
        out = out4
        return out

class build_pre_model_1(nn.Module):
    def __init__(self, pre_training_model='VGG16'):
        super(build_pre_model_1, self).__init__()
        if pre_training_model == 'MobileNetV2':
            self.model = models.mobilenet_v2(pretrained=True)
        if pre_training_model == 'ResNet50V2':
            self.model = models.resnet50(pretrained=True)
        if pre_training_model == 'VGG16':
            self.model = models.vgg16(pretrained=True)
    def forward(self, x):
        k = len(self.model.features) #31
        for i in range(k):
            x = self.model.features[i](x)
            if i == 3:
                out1 = x
            if i == 8:
                out2 = x
            if i == 15:
                out3 = x
            if i == 22:
                out4 = x
            if i == 29:
                out5 = x
        # size, size/2, size/4, size/8, size/16
        #out = [out1,out2,out3,out4,out5]

        return out1,out2,out3,out4
#canny算子提取边缘
def edge_detection_canny(map,gaussian_ksize=3,canny_th1=100,canny_th2=200):
    Map = []
    for i in map:
        i = (i*255).astype(np.uint8)
        #i = np.squeeze(i)
        #
        i = np.transpose(i, (1, 2, 0))
        i = cv2.GaussianBlur(i,(3,3),0)
        i = cv2.Canny(i, canny_th1, canny_th2)
        i = (i/255).astype(np.float32)
        i = np.expand_dims(i, axis=0)
        #cv2.imwrite("F:/cord_2/edge/1.png", i*255)

        Map.append(i)
    return Map

# def difference_operation(map1,map2):
#     Map1 = []
#     for i,j in zip(map1,map2):
#         map = cv2.absdiff(np.array(i),np.array(j))
#         #map = np.squeeze(map)
#     # 图像闭运算 = 先膨胀，再腐蚀，将断线联通
#         kernel = np.ones((3, 3))
#         map = cv2.morphologyEx(map, cv2.MORPH_CLOSE, kernel)## 有缺陷，填补缺陷
#         #map = np.expand_dims(map, axis=0)
#         #map = np.hstack((map, closing))
#         Map1.append(map)
#
#     return Map1
#
# def map_generator(img1,img2,Pre_model):
#
#     feature_map1= Pre_model(img1).detach().cpu()
#     feature_map2 = Pre_model(img2).detach().cpu()
#     am = difference_operation(feature_map1,feature_map2)
#     am = np.array(am)
#     am = torch.from_numpy(am.astype(np.float32))
#
#     esm = difference_operation(edge_detection_canny(np.array(img1.cpu())),edge_detection_canny(np.array(img2.cpu())))
#     esm = np.array(esm)
#     esm = torch.from_numpy(esm.astype(np.float32))
#
#     #esm = F.interpolate(esm, size=[512//8,512//8])
#
#     #condition =  torch.where(am > 0,1,0)
#     #esm = esm*condition
#
#     return am,esm

kernel = np.ones((3, 3))
def difference_operation(map1,map2):
    Map1 = []
    map_sum = np.abs(np.array(map1)- np.array(map2))

    for map in map_sum:
        #map = cv2.absdiff(np.array(i),np.array(j))
        #map = np.squeeze(map)
        # 图像闭运算 = 先膨胀，再腐蚀，将断线联通
        map = cv2.morphologyEx(map, cv2.MORPH_CLOSE, kernel)## 有缺陷，填补缺陷
        #map = np.expand_dims(map, axis=0)
        #map = np.hstack((map, closing))
        Map1.append(map)
    Map1 = np.array(map_sum)
    Map1 = torch.from_numpy(Map1.astype(np.float32))
    return Map1

def map_generator(img1,img2,):


    esm = difference_operation(edge_detection_canny(np.array(img1.cpu())),edge_detection_canny(np.array(img2.cpu())))


    #esm = F.interpolate(esm, size=[512//8,512//8])

    #condition =  torch.where(am > 0,1,0)
    #esm = esm*condition

    #am_out = am_2
    return esm

class edge_attention(nn.Module):
    def __init__(self,num_channel):
        super(edge_attention, self).__init__()
        self.nonliner = nn.ReLU()
        self.Sigmoid  = nn.Sigmoid()
        self.conv0    = nn.Sequential(
            nn.Conv2d(num_channel, num_channel, kernel_size=3, padding=1, bias=True),
            nn.BatchNorm2d(num_channel),
            nn.ReLU(inplace=True), )
        self.conv1 = nn.Sequential(
            nn.Conv2d(num_channel, num_channel, kernel_size=3, padding=1, bias=True),
            nn.BatchNorm2d(num_channel),
            nn.ReLU(inplace=True), )
        self.conv1_map    = nn.Sequential(
            nn.Conv2d(1, num_channel, kernel_size=3, padding=1, bias=True),
            nn.Sigmoid(),)
        #self.upsample = nn.Upsample(scale_factor=8, mode='bilinear', align_corners=True)
        self.conv2_map    = nn.Sequential(
            nn.Conv2d(1, num_channel, kernel_size=3, padding=1, bias=True),
            nn.BatchNorm2d(num_channel),
            nn.ReLU(inplace=True),)


        #self.conv3    = nn.Conv2d(64, 64, kernel_size=3, padding=1, bias=True)
        #self.conv4    = nn.Conv2d(2*64, 64, kernel_size=3, padding=1, bias=True)
        self.stage1   = nn.Sequential(
            nn.Conv2d(num_channel, 32, kernel_size=3, padding=1, bias=True),
            nn.BatchNorm2d(32),
            nn.ReLU(),
            nn.Conv2d(32, 16, kernel_size=3, padding=1, bias=True),
            nn.BatchNorm2d(16),
            nn.ReLU(),
            nn.Conv2d(16, 1, kernel_size=3, padding=1, bias=True),
            nn.Sigmoid(),
        )
    def forward(self, x1, x2):
        x = self.conv0(x1)

        Map1 = self.conv1_map(x2)
        #Map = self.upsample(Map)
        Map2 = self.conv2_map(x2)

        x = torch.multiply(x, Map1)
        x = self.conv1(x)
        x = x1+x+Map2
        # Map = self.nonliner(Map)
        # Map = self.conv3(Map)
        # Map = self.nonliner(Map)
        # Map = self.Sigmoid(Map) #max修改成sigmoid

        #x = self.conv4(torch.cat((x, Map), dim=1))
        #x = self.nonliner(x)
        x = self.stage1(x)
        return x

class change_attention(nn.Module):
    def __init__(self,in_channle,in_channle_1):
        super(change_attention, self).__init__()
        self.conv_x = nn.Sequential(
            nn.Conv2d(in_channle_1, in_channle//2, kernel_size=1, padding=0, bias=True),
            nn.BatchNorm2d(in_channle//2),
            nn.ReLU(inplace=True)
        )

        #nn.Conv2d(512, 256, kernel_size=1, padding=0, bias=True)
        self.conv_x1 = nn.Sequential(
            nn.AdaptiveAvgPool2d((1, 1)),
            nn.Conv2d(in_channle_1, in_channle//2, kernel_size=1, padding=0, bias=True),
            nn.Sigmoid() )

        self.conv_map    = nn.Sequential(
            nn.Conv2d(in_channle, in_channle//2, kernel_size=3, padding=1, bias=True),
            nn.BatchNorm2d(in_channle//2),
            nn.ReLU(inplace=True),)
        #nn.Conv2d(512, 256, kernel_size=3, padding=1, bias=True)
        self.conv_map1   = nn.Sequential(
            nn.Conv2d(in_channle//2, in_channle//2, kernel_size=3, padding=1, bias=True),
            nn.Sigmoid(),)
        #nn.Conv2d(256, 256, kernel_size=3, padding=1, bias=True)
        self.conv_map2    = nn.Sequential(
            nn.Conv2d(in_channle//2, in_channle, kernel_size=3, padding=1, bias=True),
            nn.BatchNorm2d(in_channle),
            nn.ReLU(inplace=True),)
        #nn.Conv2d(256, 512, kernel_size=1, padding=0, bias=True)

        self.conv_x2 = nn.Sequential(
            nn.Conv2d( in_channle//2, in_channle_1, kernel_size=1, padding=0, bias=True),
            nn.BatchNorm2d(in_channle_1),
            nn.ReLU(inplace=True),)

        self.conv_out = nn.Sequential(
            nn.Conv2d(in_channle +in_channle_1, in_channle_1, kernel_size=1, padding=0, bias=True),
            nn.BatchNorm2d(in_channle_1),
            nn.ReLU(inplace=True), )
    def forward(self, x, map):
        x_G = self.conv_x1(x)
        Map = self.conv_map(map)
        Map = x_G * Map
        Map1 = self.conv_map1(Map)
        Map2 = self.conv_map2(Map)

        x1 = self.conv_x(x)
        x1 = torch.multiply(x1, Map1)
        x1 = self.conv_x2(x1)+x

        x1 = torch.cat([x1,Map2],dim=1)
        x1 = self.conv_out(x1)
        return x1
"""----------------------------dcnet----------------------------------------"""

# class dcnet(nn.Module):
#     def __init__(self):
#         super(dcnet, self).__init__()
#         self.conv_1 = nn.Sequential(
#             nn.Conv2d(in_channels=6, out_channels=64, kernel_size=7, stride=1, padding=3),
#             nn.BatchNorm2d(64),
#             nn.ReLU(),)
#         self.maxpool_1 = nn.MaxPool2d((2, 2), stride=(2, 2), return_indices=True)
#         self.conv_2 = nn.Sequential(
#             nn.Conv2d(in_channels=64, out_channels=64, kernel_size=7, stride=1, padding=3),
#             nn.BatchNorm2d(64),
#             nn.ReLU(),)
#         self.maxpool_2 = nn.MaxPool2d((2, 2), stride=(2, 2), return_indices=True)
#         self.conv_3 = nn.Sequential(
#             nn.Conv2d(in_channels=64, out_channels=64, kernel_size=7, stride=1, padding=3),
#             nn.BatchNorm2d(64),
#             nn.ReLU(),)
#         self.maxpool_3 = nn.MaxPool2d((2, 2), stride=(2, 2), return_indices=True)
#         self.conv_4 = nn.Sequential(
#             nn.Conv2d(in_channels=64, out_channels=64, kernel_size=7, stride=1, padding=3),
#             nn.BatchNorm2d(64),
#             nn.ReLU(),)
#         self.maxpool_4 = nn.MaxPool2d((2, 2), stride=(2, 2), return_indices=True)
#
#         self.maxunpool_1 = nn.MaxUnpool2d(kernel_size=(2, 2), stride=(2, 2))
#         self.conv_5 = nn.Sequential(
#             nn.Conv2d(in_channels=64, out_channels=64, kernel_size=7, stride=1, padding=3),
#             nn.BatchNorm2d(64),
#             nn.ReLU(),)
#         self.maxunpool_2 = nn.MaxUnpool2d(kernel_size=(2, 2), stride=(2, 2))
#         self.conv_6 = nn.Sequential(
#             nn.Conv2d(in_channels=64, out_channels=64, kernel_size=7, stride=1, padding=3),
#             nn.BatchNorm2d(64),
#             nn.ReLU(),)
#         self.maxunpool_3 = nn.MaxUnpool2d(kernel_size=(2, 2), stride=(2, 2))
#         self.conv_7 = nn.Sequential(
#             nn.Conv2d(in_channels=64, out_channels=64, kernel_size=7, stride=1, padding=3),
#             nn.BatchNorm2d(64),
#             nn.ReLU(),)
#         self.maxunpool_4 = nn.MaxUnpool2d(kernel_size=(2,2),stride=(2,2))
#         self.conv_8 = nn.Sequential(
#             nn.Conv2d(in_channels=64, out_channels=64, kernel_size=7, stride=1, padding=3),
#             nn.BatchNorm2d(64),
#             nn.ReLU(),)
#         self.conv_out = nn.Sequential(
#             nn.Conv2d(in_channels=64, out_channels=1, kernel_size=7, stride=1, padding=3),
#             nn.Sigmoid())
#
#         self.ca = change_attention(64, 64)
#         self.ca_1 = change_attention(128, 64)
#         self.ca_2 = change_attention(256, 64)
#         self.ca_3 = change_attention(512, 64)
#         self.ea = edge_attention(64)
#
#         self.model1 = models.vgg16(pretrained=True)
#     def forward(self, input,input1,ED_MAP):
#
#         x = torch.cat([input, input1], dim=1)
#         #         FD_Map = torch.randn(x.shape[0], 192, 64, 64)
#         k = len(self.model1.features)  # 31
#         for i in range(k):
#             input = self.model1.features[i](input)
#             if i == 3:
#                 out1 = input
#             if i == 8:
#                 out2 = input
#             if i == 15:
#                 out3 = input
#             if i == 22:
#                 out4 = input
#             if i == 29:
#                 out5 = input
#
#         for i in range(k):
#             input1 = self.model1.features[i](input1)
#             if i == 3:
#                 out1_1 = input1
#             if i == 8:
#                 out2_1 = input1
#             if i == 15:
#                 out3_1 = input1
#             if i == 22:
#                 out4_1 = input1
#             if i == 29:
#                 out5_1 = input1
#         FD_Map_0 = torch.abs(out1 - out1_1)
#         FD_Map_1 = torch.abs(out2 - out2_1)
#         FD_Map_2 = torch.abs(out3 - out3_1)
#         FD_Map_3 = torch.abs(out4 - out4_1)
#
#         x1 = self.conv_1(x)
#         x1 = self.ca(x1, FD_Map_0)
#         x1, indices_1 = self.maxpool_1(x1)#/2
#         x2 = self.conv_2(x1)
#         x2 = self.ca_1(x2, FD_Map_1)
#         x2, indices_2 = self.maxpool_2(x2)#/2
#         x3 = self.conv_3(x2)
#         x3 = self.ca_2(x3, FD_Map_2)
#         x3, indices_3 = self.maxpool_3(x3)#/2
#         x4 = self.conv_4(x3)
#         x4 = self.ca_3(x4, FD_Map_3)
#         x4, indices_4 = self.maxpool_4(x4)#/2
#
#         x = self.maxunpool_1(x4,indices_4)
#         x = self.conv_5(x)
#         x = self.maxunpool_2(x, indices_3)
#         x = self.conv_6(x)
#         x = self.maxunpool_3(x, indices_2)
#         x = self.conv_7(x)
#         x = self.maxunpool_4(x, indices_1)
#         x = self.conv_8(x)
#
#         x = self.ea(x, ED_MAP)
#         #x = self.conv_out(x)
#
#         return x

features = models.vgg16(pretrained=True).features
class dcnet(nn.Module):
    def __init__(self):
        super(dcnet, self).__init__()
        self.conv_1 = nn.Sequential(
            nn.Conv2d(in_channels=6, out_channels=64, kernel_size=7, stride=1, padding=3),
            nn.BatchNorm2d(64),
            nn.ReLU(),)
        self.maxpool_1 = nn.MaxPool2d((2, 2), stride=(2, 2), return_indices=True)
        self.conv_2 = nn.Sequential(
            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=7, stride=1, padding=3),
            nn.BatchNorm2d(64),
            nn.ReLU(),)
        self.maxpool_2 = nn.MaxPool2d((2, 2), stride=(2, 2), return_indices=True)
        self.conv_3 = nn.Sequential(
            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=7, stride=1, padding=3),
            nn.BatchNorm2d(64),
            nn.ReLU(),)
        self.maxpool_3 = nn.MaxPool2d((2, 2), stride=(2, 2), return_indices=True)
        self.conv_4 = nn.Sequential(
            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=7, stride=1, padding=3),
            nn.BatchNorm2d(64),
            nn.ReLU(),)
        self.maxpool_4 = nn.MaxPool2d((2, 2), stride=(2, 2), return_indices=True)

        self.maxunpool_1 = nn.MaxUnpool2d(kernel_size=(2, 2), stride=(2, 2))
        self.conv_5 = nn.Sequential(
            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=7, stride=1, padding=3),
            nn.BatchNorm2d(64),
            nn.ReLU(),)
        self.maxunpool_2 = nn.MaxUnpool2d(kernel_size=(2, 2), stride=(2, 2))
        self.conv_6 = nn.Sequential(
            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=7, stride=1, padding=3),
            nn.BatchNorm2d(64),
            nn.ReLU(),)
        self.maxunpool_3 = nn.MaxUnpool2d(kernel_size=(2, 2), stride=(2, 2))
        self.conv_7 = nn.Sequential(
            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=7, stride=1, padding=3),
            nn.BatchNorm2d(64),
            nn.ReLU(),)
        self.maxunpool_4 = nn.MaxUnpool2d(kernel_size=(2,2),stride=(2,2))
        self.conv_8 = nn.Sequential(
            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=7, stride=1, padding=3),
            nn.BatchNorm2d(64),
            nn.ReLU(),)
        self.conv_out = nn.Sequential(
            nn.Conv2d(in_channels=64, out_channels=1, kernel_size=7, stride=1, padding=3),
            nn.Sigmoid())

        self.ca = change_attention(64, 64)
        self.ca_1 = change_attention(128, 64)
        self.ca_2 = change_attention(256, 64)
        self.ca_3 = change_attention(512, 64)
        self.ea = edge_attention(64)

        # ----------------vgg16--------------#
        self.to_relu_1_2 = nn.Sequential()
        self.to_relu_2_2 = nn.Sequential()
        self.to_relu_3_3 = nn.Sequential()
        self.to_relu_4_3 = nn.Sequential()

        for x in range(4):
            self.to_relu_1_2.add_module(str(x), features[x])  # 就是把Vgg16的[0-3]层复制给to_relu_1_2
        for x in range(4, 9):
            self.to_relu_2_2.add_module(str(x), features[x])
        for x in range(9, 16):
            self.to_relu_3_3.add_module(str(x), features[x])
        for x in range(16, 23):
            self.to_relu_4_3.add_module(str(x), features[x])  # 没有取到最后一层，一共（0-30）

    def forward(self, input,input1,ED_MAP):

        x = torch.cat([input, input1], dim=1)

        h = self.to_relu_1_2(input)
        out1 = h
        h = self.to_relu_2_2(h)
        out2 = h
        h = self.to_relu_3_3(h)
        out3 = h
        h = self.to_relu_4_3(h)
        out4 = h

        h = self.to_relu_1_2(input1)
        out1_1 = h
        h = self.to_relu_2_2(h)
        out2_1 = h
        h = self.to_relu_3_3(h)
        out3_1 = h
        h = self.to_relu_4_3(h)
        out4_1 = h

        FD_Map_0 = torch.abs(out1 - out1_1)
        FD_Map_1 = torch.abs(out2 - out2_1)
        FD_Map_2 = torch.abs(out3 - out3_1)
        FD_Map_3 = torch.abs(out4 - out4_1)

        x1 = self.conv_1(x)
        x1 = self.ca(x1, FD_Map_0)
        x1, indices_1 = self.maxpool_1(x1)#/2
        x2 = self.conv_2(x1)
        x2 = self.ca_1(x2, FD_Map_1)
        x2, indices_2 = self.maxpool_2(x2)#/2
        x3 = self.conv_3(x2)
        x3 = self.ca_2(x3, FD_Map_2)
        x3, indices_3 = self.maxpool_3(x3)#/2
        x4 = self.conv_4(x3)
        x4 = self.ca_3(x4, FD_Map_3)
        x4, indices_4 = self.maxpool_4(x4)#/2

        x = self.maxunpool_1(x4,indices_4)
        x = self.conv_5(x)
        x = self.maxunpool_2(x, indices_3)
        x = self.conv_6(x)
        x = self.maxunpool_3(x, indices_2)
        x = self.conv_7(x)
        x = self.maxunpool_4(x, indices_1)
        x = self.conv_8(x)

        x = self.ea(x, ED_MAP)
        #x = self.conv_out(x)

        return x

"""----------------------------模型实例化----------------------------------------"""
seed_torch()
unet = dcnet()
unet = unet.to(device)

"""-----------------------------数据提取与训练器------------------------------------"""

transform = transforms.Compose([
    transforms.ToTensor(),
])

class kitti_Dataset(Dataset):
    def __init__(self, transform=None):
        self.transform = transform

    def __len__(self):
        return len(os.listdir(opt.img_before_path))

    def __getitem__(self, idx):
        #a = random.randint(128,255)
        transform1 = transforms.Compose([
            transforms.ToTensor(),
            transforms.RandomRotation(180, resample=False, expand=False, center=None, fill=None, ),
            transforms.RandomResizedCrop(size=512, scale=(0.08, 2)),
        ])
        transform1_1 = transforms.Compose([
            transforms.ToTensor(),
            transforms.RandomRotation(180, resample=False, expand=False, center=None,fill=None, ),
            #transforms.RandomErasing(p=0.5, scale=(0.02, 0.33), ratio=(0.3, 3.3), value=0, inplace=False),
        ])
        transform3 = transforms.RandomChoice([transform1, transform1_1])
        transform2 = transforms.Compose([
            transforms.ToPILImage(),
            transforms.ColorJitter(brightness=0.5, contrast=0.2, saturation=0.2, hue=0.2),
            transforms.ToTensor(),
        ])

        img_name = os.listdir(opt.img_before_path)
        img_name = list(filter(file_filter, img_name))[idx]

        imgA = cv2.imread(opt.img_before_path + '/' + img_name)
        imgA = cv2.resize(imgA, (opt.image_scale_w, opt.image_scale_h))


        imgB = cv2.imread(opt.img_after_path + '/' + img_name)
        imgB = cv2.resize(imgB, (opt.image_scale_w, opt.image_scale_h))
        #imgB = np.expand_dims(imgB, 2)

        imgC = cv2.imread(opt.label_path + '/' + img_name, 0)
        imgC = cv2.resize(imgC, (opt.image_scale_w, opt.image_scale_h))
        imgC = np.expand_dims(imgC, 2)

        buff = np.concatenate([imgC,imgB,imgA], axis=2)
        buff = transform3(buff)

        imgC, imgB, imgA = buff.split([1, 3, 3], dim=0)
        imgA = transform2(imgA)
        imgB = transform2(imgB)

        return imgA,imgB,imgC
img_road = kitti_Dataset(transform)
train_dataloader = DataLoader(img_road, batch_size=opt.batch, shuffle=True)

class test_Dataset(Dataset):

    def __init__(self, transform=None):
        self.transform = transform

    def __len__(self):
        return len(os.listdir(opt.img_before_path_test))

    def __getitem__(self, idx):
        img_name = os.listdir(opt.img_before_path_test)
        img_name = list(filter(file_filter, img_name))[idx]

        imgA = cv2.imread(opt.img_before_path_test + '/' + img_name)
        imgA = cv2.resize(imgA, (opt.image_scale_w, opt.image_scale_h))

        imgB = cv2.imread(opt.img_after_path_test + '/' + img_name)
        imgB = cv2.resize(imgB, (opt.image_scale_w, opt.image_scale_h))

        if self.transform:
            imgA = self.transform(imgA)
            imgB = self.transform(imgB)

        return imgA, imgB, img_name[:-4]
img_road_test = test_Dataset(transform)
test_dataloader = DataLoader(img_road_test, batch_size=1, shuffle=False)

unet_optimizer = optim.Adam(unet.parameters(), betas=[0.5, 0.999], lr=opt.lr)
unet_scheduler = optim.lr_scheduler.MultiStepLR(unet_optimizer, milestones=[50,250,400], gamma=0.5)
"""----------------------------------------------------------------"""
def my_loss(y_true, y_pred):
    """
    Bray-Curtis distance 布雷柯蒂斯相异度
    """
    loss = torch.mean(torch.abs(y_pred - y_true)) / (torch.mean(torch.abs(y_pred + y_true)) + 0.0001)
    return loss


if opt.load_model == 'True':
    unet = torch.load(opt.model_dir)
    print("-----read_model_success-----")

loss= nn.BCELoss()

def train(device, train_dataloader, epoch):
    unet.train()
    trained_samples = 0
    for batch_idx, (road_before, road_after, label) in enumerate(train_dataloader):

        road_before, road_after, label= road_before.to(device), road_after.to(device), label.to(device)
        ED_MAP = map_generator(road_before, road_after)
        ED_MAP =  ED_MAP.to(device)

        detect = unet(road_before, road_after, ED_MAP)
        unet_loss = loss(detect,label)

        unet_optimizer.zero_grad()
        unet_loss.backward()
        unet_optimizer.step()

        progress = math.ceil(batch_idx / len(train_dataloader) * 50)
        trained_samples += len(road_before)
        if batch_idx % 200 == 0:
            tqdm.write('[{}/{}] [{}/{}] Loss: {:.6f} '.format(epoch, num_epochs, batch_idx, len(train_dataloader), unet_loss.data.item()))
        print('\rTrain epoch: {} {}/{} [{}]{}%'.format(epoch, trained_samples, len(train_dataloader.dataset),'-' * progress + '>', progress * 2), end='')

        #torch.cuda.empty_cache()


def test(device, test_dataloader):
    unet.eval()
    begin_time = time.time()

    for batch_idx, (road_before, road_after,img_name) in enumerate(test_dataloader):

        road_before, road_after= road_before.to(device), road_after.to(device)
        ED_MAP = map_generator(road_before, road_after)
        ED_MAP =  ED_MAP.to(device)
        with torch.no_grad():
            det_road = unet(road_before, road_after, ED_MAP)
            predict = det_road.cpu()
            predict = np.array(predict)
            predict = np.where(predict > 0.5, 1, 0)
            predict = np.squeeze(predict)
            cv2.imwrite(opt.result+str(img_name[0])+".png", predict * 255)
    print('Done!')
    end_time = time.time()
    runtime = end_time - begin_time
    print('running time:', runtime)


def iou(path_pre, path_lab):
    begin_time = time.time()

    img_name = os.listdir(path_pre)
    img_name = list(filter(file_filter, img_name))

    iou_list = []
    p_list = []
    r_list = []
    F1_list = []
    acc_list = []

    for i in range(len(img_name)):
        det = img_name[i]
        det = cv2.imread(path_pre + det, 0)

        lab = img_name[i]
        lab = cv2.imread(path_lab + lab, 0)
        lab = cv2.resize(lab, (opt.image_scale_w, opt.image_scale_h))

        count0, count1, count2, count3 = 0, 0, 0, 0
        for j in range(det.shape[0]):
            for k in range(det.shape[1]):
                # TP
                if det[j][k] != 0 and lab[j][k] != 0:
                    count0 += 1
                # FN
                elif det[j][k] == 0 and lab[j][k] != 0:
                    count1 += 1
                # FP
                elif det[j][k] != 0 and lab[j][k] == 0:
                    count2 += 1
                # TN
                elif det[j][k] == 0 and lab[j][k] == 0:
                    count3 += 1
        iou = count0 / (count1 + count0 + count2 + 0.0001)
        p = count0 / (count0 + count2 + 0.0001)
        r = count0 / (count0 + count1 + 0.0001)
        acc = (count0 + count3)/ (count1 + count0 + count2 + count3 + 0.0001)
        F1 = 2 * (p * r) / (p + r + 0.0001)

        iou_list.append(iou)
        p_list.append(p)
        r_list.append(r)
        F1_list.append(F1)
        acc_list.append(acc)

    print('Done!')
    end_time = time.time()
    runtime = end_time - begin_time
    print('running time:', runtime)
    return np.mean(iou_list),np.mean(p_list),np.mean(r_list),np.mean(F1_list),np.mean(acc_list)


def iou_2(path_pre, path_lab):
    begin_time = time.time()

    img_name = os.listdir(path_pre)
    img_name = list(filter(file_filter, img_name))

    iou_list_1 = []
    p_list_1 = []
    r_list_1 = []
    F1_list_1 = []
    acc_list_1 = []
    for i in range(len(img_name)):
        det = img_name[i]
        det = cv2.imread(path_pre + '/' + det, 0)
        det_1 = np.where(det != 0, 1, 0)
        lab = img_name[i]
        lab = cv2.imread(path_lab + '/' + lab, 0)
        lab = cv2.resize(lab, (opt.image_scale_w, opt.image_scale_h))
        lab_1 = np.where(lab != 0, 1, 0)
        # TP
        count_0 = (det_1 * lab_1).sum()
        # FN
        count_1 = ((1 - det_1) * lab_1).sum()
        # FP
        count_2 = (det_1 * (1 - lab_1)).sum()
        # TN
        count_3 = ((1 - det_1) * (1 - lab_1)).sum()

        iou_1 = count_0 / (count_1 + count_0 + count_2 + 0.0001)
        p_1 = count_0 / (count_0 + count_2 + 0.0001)
        r_1 = count_0 / (count_0 + count_1 + 0.0001)
        acc_1 = (count_0 + count_3) / (count_1 + count_0 + count_2 + count_3 + 0.0001)
        F1_1 = 2 * (p_1 * r_1) / (p_1 + r_1 + 0.0001)

        iou_list_1.append(iou_1)
        p_list_1.append(p_1)
        r_list_1.append(r_1)
        F1_list_1.append(F1_1)
        acc_list_1.append(acc_1)

    print('Done!')
    end_time = time.time()
    runtime = end_time - begin_time
    print('running time_1:', runtime)

    return np.mean(iou_list_1), np.mean(p_list_1), np.mean(r_list_1), np.mean(F1_list_1), np.mean(acc_list_1)

def iou_1(path_pre, path_lab):
    begin_time = time.time()

    img_name = os.listdir(path_pre)
    img_name = list(filter(file_filter, img_name))

    count0 = []
    count1 = []
    count2 = []
    count3 = []
    #acc_list_1 = []
    for i in range(len(img_name)):
        det = img_name[i]
        det = cv2.imread(path_pre + '/' + det, 0)
        det_1 = np.where(det != 0, 1, 0)
        lab = img_name[i]
        lab = cv2.imread(path_lab + '/' + lab, 0)
        lab = cv2.resize(lab, (opt.image_scale_w, opt.image_scale_h))
        lab_1 = np.where(lab != 0, 1, 0)
        # TP
        count_0 = (det_1 * lab_1).sum()
        # FN
        count_1 = ((1 - det_1) * lab_1).sum()
        # FP
        count_2 = (det_1 * (1 - lab_1)).sum()
        # TN
        count_3 = ((1 - det_1) * (1 - lab_1)).sum()

        count0.append(count_0)
        count1.append(count_1)
        count2.append(count_2)
        count3.append(count_3)
        #acc_list_1.append(acc_1)
    count0_0 = np.sum(count0)
    count1_0 = np.sum(count1)
    count2_0 = np.sum(count2)
    count3_0 = np.sum(count3)

    iou_1 = count0_0 / (count1_0 + count0_0 + count2_0 + 0.0001)
    p_1 = count0_0 / (count0_0 + count2_0 + 0.0001)
    r_1 = count0_0 / (count0_0 + count1_0 + 0.0001)
    acc_1 = (count0_0 + count3_0) / (count1_0 + count0_0 + count2_0 + count3_0 + 0.0001)
    F1_1 = 2 * (p_1 * r_1) / (p_1 + r_1 + 0.0001)
    print('Done!')
    end_time = time.time()
    runtime = end_time - begin_time
    print('running time_1:', runtime)

    return iou_1, p_1, r_1, F1_1, acc_1


if __name__ == '__main__':

    if opt.mode == 'train':
        num_epochs = opt.num_epochs
        with open(opt.txt, "a") as f:
            f.write("5_1"  + '\n')
        f1_max = 0
        Miou_max = 0
        for epoch in tqdm(range(num_epochs)):
            train(device, train_dataloader, epoch)
            unet_scheduler.step()
            if epoch % 5 == 0:
                torch.save(unet, opt.model_dir)
                print('testing...')
                test(device, test_dataloader)
                #Miou, pre, recall, F1, acc= iou(opt.result, opt.label_path_test)
                Miou, pre, recall, F1, acc = iou_1(opt.result, opt.label_path_test)
                print('mean_iou:', Miou, 'mean_pre:', pre, 'mean_recall:', recall, 'mean_F1:', F1, 'acc:', acc)


                # print('mean_iou_1:', Miou_1, 'mean_pre_1:', pre_1, 'mean_recall_1:', recall_1, 'mean_F1_1:', F1_1, 'acc_1:', acc_1)

                if F1 > f1_max or Miou > Miou_max:
                    f1_max = F1
                    Miou_max = Miou
                    torch.save(unet, opt.model_dir_max)
                    for name in os.listdir(opt.result):
                        shutil.copy(opt.result + '/' + name, opt.result_max + '/' + name)
                with open(opt.txt, "a") as f:
                    f.write("model_num" + " " + str(epoch) + '  mean_iou:' + str(Miou) + '  mean_pre:' + str(
                        pre) + '  mean_recall:' + str(recall) + '  mean_F1:' + str(F1) + '  acc:' + str(acc) +'\n')

                    # f.write("model_num" + " " + str(epoch) + '  mean_iou_1:' + str(Miou_1) + '  mean_pre_1:' + str(
                    #     pre_1) + '  mean_recall_1:' + str(recall_1) + '  mean_F1_1:' + str(F1_1) + '  acc_1:' + str(acc_1) + '\n')

    if opt.mode == 'test':
        test(device, test_dataloader)
        Miou, pre, recall, F1, acc = iou_1(opt.result, opt.label_path_test)
        print('mean_iou:', Miou, 'mean_pre:', pre, 'mean_recall:', recall, 'mean_F1:', F1, 'acc:', acc)





# #特征可视化
# def difference_operation(map1,map2):
#     map1 = np.array(map1[0].detach().cpu())
#     map2 = np.array(map2[0].detach().cpu())
#     map = cv2.absdiff(map1,map2)
#     # 图像闭运算 = 先膨胀，再腐蚀，将断线联通
#     kernel = np.ones((3, 3), dtype=np.uint8)
#     map = cv2.morphologyEx(map, cv2.MORPH_CLOSE, kernel)  ## 有缺陷，填补缺陷
#     #map = np.hstack((map, closing))
#     return map
#
# def heatmap(fea,name):
#
#     fea = fea#4,256,32,32
#     #fea2 = utils.make_grid(fea, nrow=IMG_CUT, padding=0)
#     #g = torch.nn.functional.adaptive_avg_pool2d(fea, (1, 1))
#     fea1 = np.array(fea)#32,128,256
#     #g = np.array(g[0])
#     #fea1 = fea1*g
#     heatmap1 = np.maximum(fea1, 0)
#     #heatmap1 = np.max(fea1, axis=0)
#     # heatmap与0比较，取其大者
#     heatmap = np.mean(heatmap1, axis=0) # shape为[256,256]，二维
#     #.reshape(256, 256)
#     #heatmap = np.where(heatmap > 0.9, 1, heatmap)
#     heatmap = (((heatmap - np.min(heatmap)) / (np.max(heatmap) - np.min(heatmap)))*255).astype(np.uint8) # 归一化并映射到0-255的整数，方便伪彩色化
#     #heatmap = (( heatmap)* 255).astype(np.uint8)
#     # heatmap = utils.make_grid(heatmap, nrow=IMG_CUT, padding=0)
#
#     heatmap = cv2.resize(heatmap,(256,256))
#     #heatmap = (heatmap*255).astype(np.uint8)
#     #img = cv2.imread(img_path)
#
#     # heatmap = cv2.resize(heatmap, (road_np.shape[1], road_np.shape[0]))
#     #heatmap = np.uint(255 * heatmap)
#     heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)
#
#     #super_map = heatmap * 0.4 + road_np
#     cv2.imwrite("F:/cord1/eyes_sum//{}.png".format(name), heatmap)
#
# if __name__ == '__main__':
#     for i in os.listdir("F:/5_1/5_1/train/after/"):
#         imgA = cv2.imread("F:/5_1/5_1/train/after/{}".format(i))
#         imgA = torch.tensor(imgA/255)
#         imgB = cv2.imread("F:/5_1/5_1/train/before/{}".format(i))
#         imgB = torch.tensor(imgB / 255)
#         imgA = imgA.permute(2, 0, 1).unsqueeze(0).type(torch.FloatTensor)
#         imgB = imgB.permute(2, 0, 1).unsqueeze(0).type(torch.FloatTensor)
#         imgA, imgB = imgA.to(device), imgB.to(device)
#         A_fea = Pre_model(imgA)
#         B_fea = Pre_model(imgB)
#         for j in range(5):
#             out = difference_operation(A_fea[j],B_fea[j])
#             heatmap(A_fea[j][0].detach().cpu(),str(i[:-4])+"_after_"+str(j))
#             heatmap(B_fea[j][0].detach().cpu(),str(i[:-4])+"_before_"+str(j))
#             heatmap(out, str(i[:-4])+"_diff_"+str(j))
#         lab = cv2.imread("F:/5_1/5_1/train/change_label/{}".format(i))
#         cv2.imwrite("F:/cord1/eyes_sum/{}.png".format(i), lab)



